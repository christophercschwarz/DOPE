---
title: "Distributions of Possible Effects"
output: rmarkdown::github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, echo = FALSE}
knitr::opts_chunk$set(collapse=TRUE, comment="##", fig.retina=2, fig.path = "README_figs/README-")
```

### Why should I use it?

The threat of endogeneity is ubiquitous within applied empirical research.  Regressor-error dependencies are a common inferential concern not in the least because they may arise from any combination of omitted variable, systematic measurement errors, self selection, systematic missing data, reciprocal causation, or interference between units.  Conventional statistical methods do not reflect any source of uncertainty other than random error and so do not express these additional doubts.  The package impliments a "near Bayesian" method of sensitivity analysis which samples uniformly from the set of valid control functions to build a distribution of possible causal effects as well as graphical tools for assessing the sensitivity of one's results to the threat of hidden biases.

### How do I get it?

Until the package is released on CRAN you can install the developmental version of the package with the following lines of code:
```{r message=FALSE, warning=FALSE}
Sys.setenv("R_REMOTES_NO_ERRORS_FROM_WARNINGS"=TRUE)
devtools::install_github("christophercschwarz/DOPE",
                         dependencies=TRUE)
library(DOPE)
```

### How do I use it?

The DOPE algorithm is built upon linear regression targeting uncertainty in the ATE.  The approach can be extended to semi-parametric distributional regression models, possibly including random effects, for various estimands with relative ease utilizing whitening and augmentation tricks to put the models in OLS form.  

To illustrate a number of functions from the package, let's look at a simulated example.  First, let's generate a random correlation matrix, generate some data, and run a linear model.

```{r}
set.seed(8675309)
x_vars <- 5
n_obs <- 1000
corm <- RandomCormCPP(nvars = x_vars)
X_mat <- MASS::mvrnorm(n_obs, rep(0,x_vars), Sigma = corm, empirical = TRUE)

betas <- 1:x_vars

y <- X_mat %*% betas + rnorm(n_obs, 0, 1)

dat <- data.frame(y,X_mat)
cov(dat)
```

Now let's estimate a model.
```{r}
mod <- lm(y ~ ., data=dat)
```

Since we have control over the process by which the data was generated we know that the model is correct and that the coefficients are unbiased/consistent estimates of the treatment effect of interest.  Suppose, however, that we did not.  We can take draws from the set of valid control functions to build out a distribution of possible effects reflecting ignorance of the regressor-error dependency plaguing our analysis.  The number of draws can be set with `nsims` and the number of cores for parallel computation with `n.cores`.

```{r results=FALSE}
dope <- DOPE(mod, nsims = 3000, n.cores = parallel::detectCores())
```

The result is a dataframe of `nsims` + 1 observations with columns for each of the estimated coefficients, the control function coefficient, and model R-squared.  The last observation simply re-states the results from the naive model for use in plotting functions.  The most basic plot shows the simulated distribution of possible effects and gives a number of useful summaries.  Because these are `ggplot` objects, that can be easily modified by adding additional layers.

```{r}
plot_DOPE(dope,"V2") + ggtitle("Distribution of Possible Effects: V2")
```

In this example, based upon 3000 draws 84.23% of the estimated effects are greater than zero with a 95% credible interval of -4.58 to 9.13.  The naive estimate is indicated in red.  Because these quantities are generated from random draws it is always a good idea to set a seed, although they stabalize with a larger amount of random draws.

We can get a little bit more information from the plot by shading based upon the R-squared from each regression and turning off the naive result.

```{r}
plot_DOPE(dope,"V2",shade=T,include_naive = F) + ggtitle("Distribution of Possible Effects: V2")
```

Lighter shades indicate lower R-squared than darker shades, given a sense for how fits are distributed across the effect values.  This is important as the distribution of possible effects changes as a function of the allowable R-squared.  If we wanted to change the color away from greyscale we can add another layer like so:

```{r}
plot_DOPE(dope,"V2",shade=T,include_naive = F) + ggtitle("Distribution of Possible Effects: V2") + scale_fill_discrete()
```

Gross.  Anyway, we can get a sense for how these things change with a sensitivity plot.

```{r}
sensitivity_plot(dope,"V2")
```